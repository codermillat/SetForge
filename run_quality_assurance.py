#!/usr/bin/env python3
"""
SetForge Quality Assurance Pipeline (Part 3)
Performs quality checks, starting with deduplication, on the generated dataset.
"""

import json
import logging
import os
from typing import Set, Dict, Any

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

class QualityAssurance:
    """
    A pipeline for performing quality assurance tasks on the generated dataset.
    """

    def __init__(self, input_file: str, output_file: str):
        """
        Initializes the QualityAssurance pipeline.

        Args:
            input_file: Path to the input .jsonl dataset file.
            output_file: Path to the output .jsonl file for the cleaned dataset.
        """
        self.input_file = input_file
        self.output_file = output_file
        self.seen_questions: Set[str] = set()
        self.total_lines = 0
        self.duplicates_found = 0

    def _normalize_question(self, question: str) -> str:
        """
        Normalizes a question string for more effective duplicate detection.
        - Converts to lowercase.
        - Removes leading/trailing whitespace.
        - Removes common punctuation to catch near-identical questions.
        """
        normalized = question.lower().strip()
        # Remove punctuation that might cause false negatives
        for p in '?.!,-':
            normalized = normalized.replace(p, '')
        return normalized

    def run_deduplication(self):
        """
        Reads the input dataset, removes duplicate entries based on the
        normalized question text, and writes the unique entries to the output file.
        """
        logging.info(f"üöÄ Starting Quality Assurance Pipeline: Deduplication")
        logging.info(f"Input file: {self.input_file}")
        logging.info(f"Output file: {self.output_file}")

        try:
            # Ensure the output directory exists
            output_dir = os.path.dirname(self.output_file)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)

            with open(self.input_file, 'r', encoding='utf-8') as infile, \
                 open(self.output_file, 'w', encoding='utf-8') as outfile:

                for line in infile:
                    self.total_lines += 1
                    try:
                        qa_pair: Dict[str, Any] = json.loads(line.strip())
                        question = qa_pair.get("question")

                        if not question or not isinstance(question, str):
                            logging.warning(f"Skipping malformed record on line {self.total_lines}: {line.strip()}")
                            continue

                        normalized_question = self._normalize_question(question)

                        if normalized_question not in self.seen_questions:
                            self.seen_questions.add(normalized_question)
                            outfile.write(line)
                        else:
                            self.duplicates_found += 1

                    except json.JSONDecodeError:
                        logging.warning(f"Could not decode JSON on line {self.total_lines}. Skipping.")
                        continue
            
            logging.info("‚úÖ Deduplication process completed.")
            logging.info(f"üìä Statistics:")
            logging.info(f"   - Total lines read: {self.total_lines}")
            logging.info(f"   - Duplicate questions found and removed: {self.duplicates_found}")
            logging.info(f"   - Unique Q&A pairs written: {self.total_lines - self.duplicates_found}")

        except FileNotFoundError:
            logging.error(f"‚ùå Error: Input file not found at '{self.input_file}'")
        except Exception as e:
            logging.error(f"‚ùå An unexpected error occurred: {e}", exc_info=True)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Run the SetForge Quality Assurance (Deduplication) Pipeline.")
    parser.add_argument(
        '--input',
        type=str,
        default='data_qa/qna_dataset.jsonl',
        help='Path to the input JSONL file generated by the Q&A Forge.'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='dataset/dataset.jsonl',
        help='Path to the final, deduplicated JSONL dataset file.'
    )
    args = parser.parse_args()

    qa_pipeline = QualityAssurance(input_file=args.input, output_file=args.output)
    qa_pipeline.run_deduplication()
